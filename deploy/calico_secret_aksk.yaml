---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: calico-node
  namespace: kube-system

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: calico-node
rules:
- apiGroups:
  - ""
  resources:
  - serviceaccounts/token
  verbs:
  - get
  - watch
  - create
- apiGroups:
  - ""
  resources:
  - namespaces
  - serviceaccounts
  - configmaps
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - pods/status
  verbs:
  - update
  - patch
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
  - patch
- apiGroups:
  - ""
  resources:
  - services
  verbs:
  - get
  - list
- apiGroups:
  - ""
  resources:
  - endpoints
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - nodes
  - nodes/status
  verbs:
  - get
  - list
  - update
  - watch
  - patch
- apiGroups:
  - discovery.k8s.io
  resources:
  - endpointslices
  verbs:
  - get
  - list
- apiGroups:
  - networking.k8s.io
  resources:
  - networkpolicies
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - crd.projectcalico.org
  resources:
  - globalfelixconfigs
  - felixconfigurations
  - bgppeers
  - globalbgpconfigs
  - globalnetworksets
  - hostendpoints
  - bgpconfigurations
  - ippools
  - globalnetworkpolicies
  - networkpolicies
  - networksets
  - clusterinformations
  - ipamblocks
  - ipamhandles
  - caliconodestatuses
  verbs:
  - create
  - get
  - list
  - update
  - watch

---

# Bind the calico ClusterRole to the canal ServiceAccount.
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: calico-node
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: calico-node
subjects:
- kind: ServiceAccount
  name: calico-node
  namespace: kube-system

---

apiVersion: v1
data:
  calico_iface: ""
  monitor_token: "false"
  cni_network_config: |-
    {
      "name": "k8s-pod-network",
      "cniVersion": "0.3.0",
      "plugins": [
        {
          "type": "calico",
          "log_level": "info",
          "datastore_type": "kubernetes",
          "nodename": "__KUBERNETES_NODE_NAME__",
          "nodename_file_optional": true,
          "ipam": {
            "type": "host-local",
            "subnet": "usePodCidr"
          },
          "policy": {
              "type": "k8s"
          },
          "kubernetes": {
              "kubeconfig": "__KUBECONFIG_FILEPATH__"
          }
        },
        {
          "type": "portmap",
          "capabilities": {"portMappings": true}
        },
        {
          "type": "bandwidth",
          "capabilities":{
            "bandwidth":true
          }
        }
      ]
    }
  masquerade: "false"
  net-conf.json: |
    {
      "Backend": {
        "kop_auth": true,
        "Type": "ksc-vpc",
        "neutron_endpoint": "http://internal.api.ksyun.com",
        "app_endpoint": "http://internal.api.ksyun.com"
      }
    }
kind: ConfigMap
metadata:
  name: calico-config
  namespace: kube-system

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    k8s-app: calico-cni
  name: calico-cni
  namespace: kube-system
spec:
  selector:
    matchLabels:
      k8s-app: calico-cni
  template:
    metadata:
      labels:
        k8s-app: calico-cni
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: type
                operator: NotIn
                values:
                - virtual-kubelet
      containers:
      - env:
        - name: CNI_CONF_NAME
          value: 10-calico.conflist
        - name: KUBERNETES_NODE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: spec.nodeName
        - name: CNI_NETWORK_CONFIG
          valueFrom:
            configMapKeyRef:
              key: cni_network_config
              name: calico-config
        - name: MONITOR_TOKEN
          valueFrom:
            configMapKeyRef:
              key: monitor_token
              name: calico-config
        image: hub.kce.ksyun.com/ksyun/calico/cni:v3.24.6-for-selfbuild-cluster
        imagePullPolicy: Always
        name: install-cni
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /host/opt/cni/bin
          name: cni-bin-dir
        - mountPath: /host/etc/cni/net.d
          name: cni-net-dir
      initContainers:
        - image: hub.kce.ksyun.com/ksyun/vpc-route-controller/annotation:v1.0.0
          name: annotation
          imagePullPolicy: Always
          env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
      dnsPolicy: ClusterFirst
      hostNetwork: true
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: calico-node
      priorityClassName: system-node-critical
      serviceAccountName: calico-node
      terminationGracePeriodSeconds: 0
      tolerations:
      - operator: Exists
      - key: CriticalAddonsOnly
        operator: Exists
      - effect: NoExecute
        operator: Exists
      volumes:
      - hostPath:
          path: /opt/cni/bin
          type: ""
        name: cni-bin-dir
      - hostPath:
          path: /etc/cni/net.d
          type: ""
        name: cni-net-dir
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 1
    type: RollingUpdate
    
---
apiVersion: v1
data:
  config: '{"NonMasqueradeCIDRs":["___POD_CIDR___","___VPC_CIDR___"],"MasqLinkLocal":true,"ResyncInterval":"1m0s"}'
kind: ConfigMap
metadata:
  name: ip-masq-agent-config
  namespace: kube-system

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: ip-masq-agent
  namespace: kube-system
spec:
  selector:
    matchLabels:
      k8s-app: ip-masq-agent
  template:
    metadata:
      labels:
        k8s-app: ip-masq-agent
    spec:
      tolerations:
      - operator: Exists
      hostNetwork: true
      containers:
      - name: ip-masq-agent
        image: hub.kce.ksyun.com/ksyun/ip-masq-agent-amd64:v2.0.0
        securityContext:
          privileged: false
          capabilities:
            add: ["NET_ADMIN", "NET_RAW"]
        volumeMounts:
          - name: config
            mountPath: /etc/config
      volumes:
        - name: config
          configMap:
            # Note this ConfigMap must be created in the same namespace as the daemon pods - this spec uses kube-system
            name: ip-masq-agent-config
            optional: true
            items:
              # The daemon looks for its config in a YAML file at /etc/config/ip-masq-agent
              - key: config
                path: ip-masq-agent

---
# vpc-route-controller roles
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: vpc-route-controller
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - get
  - apiGroups:
      - ""
    resources:
      - nodes
      - nodes/status
      - events
    verbs:
      - list
      - get
      - patch
      - create
      - watch
  - apiGroups:
      - "coordination.k8s.io"
    resources:
      - leases
    verbs:
      - get
      - create
      - update

---

# Bind the flannel ClusterRole to the canal ServiceAccount.
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: vpc-route-controller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: vpc-route-controller
subjects:
- kind: ServiceAccount
  name: vpc-route-controller
  namespace: kube-system

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: vpc-route-controller
  namespace: kube-system
---

kind: ConfigMap
apiVersion: v1
metadata:
  name: vpc-route-controller-conf
  namespace: "kube-system"
  labels:
    tier: node
    app: vpc-route-controller
data:
  net-conf: |
    {
      "region": "___REGION___",
      "vpc_id": "___VPC_ID___",
      "cluster_uuid": "___CLUSTER_UUID___",
      "network_endpoint": "http://internal.api.ksyun.com",
      "aksk_type": "file"
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vpc-route-controller
  namespace: "kube-system"
  labels:
    tier: node
    k8s-app: vpc-route-controller
spec:
  selector:
    matchLabels:
      tier: node
      k8s-app: vpc-route-controller
  replicas: 1
  strategy:
    rollingUpdate:
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      labels:
        tier: node
        k8s-app: vpc-route-controller
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: type
                operator: NotIn
                values:
                - virtual-kubelet
      serviceAccountName: vpc-route-controller
      hostNetwork: true
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
               matchExpressions:
               - {key: k8s-app, operator: In, values: ["vpc-route-controller"]}
            topologyKey: kubernetes.io/hostname
      containers:
      - name: vpc-route-controller
        image: hub.kce.ksyun.com/ksyun/vpc-route-controller:v1.0.0-common
        imagePullPolicy: Always
        resources:
          limits:
            cpu: 300m
            memory: 500M
          requests:
            cpu: 150m
            memory: 64M
        command: [ "/usr/bin/vpc-route-controller" ]
        securityContext:
          privileged: true
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: NET_CONF 
          valueFrom:
            configMapKeyRef:
              name: vpc-route-controller-conf
              key: net-conf
        volumeMounts:
        - name: cni
          mountPath: /etc/cni/net.d
        - name: aksk
          mountPath: /var/lib/aksk
      tolerations:
        # Make sure canal gets scheduled on all nodes.
        - operator: Exists
        # Mark the pod as a critical add-on for rescheduling.
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoExecute
          operator: Exists
      volumes:
        - name: cni
          hostPath:
            path: /etc/cni/net.d
        - name: net-conf
          configMap:
            name: vpc-route-controller-conf
        - name: aksk
          secret:
            secretName: kce-security-token
            
---
